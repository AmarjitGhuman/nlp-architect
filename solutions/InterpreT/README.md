# InterpreT: An Interactive Visualization Tool for Interpreting Transformers
## Part of NLP Architect by IntelÂ® AI Lab

## Overview

As Transformers have become the de-facto standard for NLU/NLP tasks, there has been growing interest in understanding the inner-workings of these models as well as why they are so effective at such tasks. In order to further this goal of explainability and understanding, we present InterpreT. Our system is designed to facilitate such understanding of the behavior of Transformers models. Although our system is meant to be a general tool for understanding, for brevity we demonstrate our system's functionality through analyzing model behavior for specific and separate tasks, namely the Winograd Schema Challenge (WSC) and for Aspect Based Sentiment Analysis (ABSA). By enabling analysis through probing and visualizing the internal representations of Transformer models, our system allows users to draw insights into how and what their models are learning. 

## Video Demo

[![Video Demo](https://raw.githubusercontent.com/IntelLabs/nlp-architect/master/solutions/absa_solution/assets/video.png)](https://drive.google.com/open?id=1BLk0xkjIOqyRhNy4UQEFQpDF_KR_NMAd)
*Figure 1*
